<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes By Example</title>
    <link>https://tonejito.github.io/kbe/</link>
    <description>Recent content on Kubernetes By Example</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 10 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://tonejito.github.io/kbe/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DIY</title>
      <link>https://tonejito.github.io/kbe/diy/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/diy/</guid>
      <description>If you want to try out the examples here yourself, here are a couple of options:
OpenShift Playground You can use the OpenShift Playground to get access to a cluster for 60 minutes at a time. This option doesn&amp;rsquo;t require you to install anything. This is the option we used for most of the examples on the site.
OpenShift Playground
Click the red START SCENARIO button, and then you will have access to an OpenShift cluster via a web-based terminal window with kubectl available.</description>
    </item>
    
    <item>
      <title>Namespaces</title>
      <link>https://tonejito.github.io/kbe/ns/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/ns/</guid>
      <description>Namespaces provide a scope for Kubernetes resources, carving up your cluster in smaller units. You can think of it as a workspace you&amp;rsquo;re sharing with other users. Many resources such as pods and services are namespaced, while some, for example, nodes are not namespaced (but cluster-wide). As a developer you&amp;rsquo;d usually use an assigned namespace, however admins may wish to manage them, for example to set up access control or resource quotas.</description>
    </item>
    
    <item>
      <title>Nodes</title>
      <link>https://tonejito.github.io/kbe/nodes/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/nodes/</guid>
      <description>In Kubernetes, nodes are the (virtual) machines where your workloads in shape of pods run. As a developer you typically don&amp;rsquo;t deal with nodes directly, however as an admin you might want to familiarize yourself with node operations.
To list available nodes in your cluster (note that the output will depend on the environment you&amp;rsquo;re using. This example is using the OpenShift Playground):
kubectl get nodes NAME STATUS ROLES AGE VERSION crc-rk2fc-master-0 Ready master,worker 102d v1.</description>
    </item>
    
    <item>
      <title>StatefulSet</title>
      <link>https://tonejito.github.io/kbe/statefulset/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/statefulset/</guid>
      <description>If you have a stateless app you want to use a deployment. However, for a stateful app you might want to use a StatefulSet. Unlike a deployment, the StatefulSet provides certain guarantees about the identity of the pods it is managing (that is, predictable names) and about the startup order. Two more things that are different compared to a deployment: for network communication you need to create a headless services and for persistency the StatefulSet manages a persistent volume per pod.</description>
    </item>
    
    <item>
      <title>Jobs</title>
      <link>https://tonejito.github.io/kbe/jobs/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/jobs/</guid>
      <description>A job in Kubernetes is a supervisor for pods carrying out batch processes, that is, a process that runs for a certain time to completion, for example a calculation or a backup operation.
Let&amp;rsquo;s create a job called countdown that supervises a pod counting from 9 down to 1:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/jobs/job.yaml You can see the job and the pod it looks after like so:
kubectl get jobs NAME DESIRED SUCCESSFUL AGE countdown 1 1 5s kubectl get pods NAME READY STATUS RESTARTS AGE countdown-qkjx8 0/1 Completed 0 2m17s To learn more about the status of the job, do:</description>
    </item>
    
    <item>
      <title>Volumes</title>
      <link>https://tonejito.github.io/kbe/volumes/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/volumes/</guid>
      <description>A Kubernetes volume is essentially a directory accessible to all containers running in a pod. In contrast to the container-local filesystem, the data in volumes is preserved across container restarts. The medium backing a volume and its contents are determined by the volume type:
 node-local types such as emptyDir or hostPath file-sharing types such as nfs cloud provider-specific types like awsElasticBlockStore, azureDisk, or gcePersistentDisk distributed file system types, for example glusterfs or cephfs special-purpose types like secret, gitRepo  A special type of volume is PersistentVolume, which we will cover elsewhere.</description>
    </item>
    
    <item>
      <title>API Server access</title>
      <link>https://tonejito.github.io/kbe/api/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/api/</guid>
      <description>Sometimes it&amp;rsquo;s useful or necessary to directly access the Kubernetes API server, for exploratory or testing purposes.
In order to do this, one option is to proxy the API to your local environment, using:
kubectl proxy --port=8080 Starting to serve on 127.0.0.1:8080 Now you can query the API (in a separate terminal session) like so:
curl http://localhost:8080/api/v1 { &amp;quot;kind&amp;quot;: &amp;quot;APIResourceList&amp;quot;, &amp;quot;groupVersion&amp;quot;: &amp;quot;v1&amp;quot;, &amp;quot;resources&amp;quot;: [ { ... { &amp;quot;name&amp;quot;: &amp;quot;services/status&amp;quot;, &amp;quot;singularName&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;namespaced&amp;quot;: true, &amp;quot;kind&amp;quot;: &amp;quot;Service&amp;quot;, &amp;quot;verbs&amp;quot;: [ &amp;quot;get&amp;quot;, &amp;quot;patch&amp;quot;, &amp;quot;update&amp;quot; ] } ] } Alternatively, without proxying, you can use kubectl directly as follows to achieve the same:</description>
    </item>
    
    <item>
      <title>Pods</title>
      <link>https://tonejito.github.io/kbe/pods/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/pods/</guid>
      <description>A pod is a collection of containers sharing a network and mount namespace and is the basic unit of deployment in Kubernetes. All containers in a pod are scheduled on the same node.
To launch a pod using the container image quay.io/openshiftlabs/simpleservice:0.5.0 and exposing a HTTP API on port 9876, execute:
kubectl run sise --image=quay.io/openshiftlabs/simpleservice:0.5.0 --port=9876 pod/sise created Note: Deprecation Warning! Older releases of kubectl will produce a deployment resource as the result of the provided kubectl run example, while newer releases produce a single pod resource.</description>
    </item>
    
    <item>
      <title>Logging</title>
      <link>https://tonejito.github.io/kbe/logging/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/logging/</guid>
      <description>Logging is one option to understand what is going on inside your applications and the cluster at large. Basic logging in Kubernetes makes the output a container produces available, which is a good use case for debugging. More advanced setups consider logs across nodes and store them in a central place, either within the cluster or via a dedicated (cloud-based) service.
Let&amp;rsquo;s create a pod called logme that runs a container writing to stdout and stderr:</description>
    </item>
    
    <item>
      <title>Secrets</title>
      <link>https://tonejito.github.io/kbe/secrets/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/secrets/</guid>
      <description>You don&amp;rsquo;t want sensitive information such as a database password or an API key kept around in clear text. Secrets provide you with a mechanism to use such information in a safe and reliable way with the following properties:
 Secrets are namespaced objects, that is, exist in the context of a namespace You can access them via a volume or an environment variable from a container running in a pod The secret data on nodes is stored in tmpfs volumes A per-secret size limit of 1MB exists The API server stores secrets as plaintext in etcd  Let&amp;rsquo;s create a secret apikey that holds a (made-up) API key:</description>
    </item>
    
    <item>
      <title>Deployments</title>
      <link>https://tonejito.github.io/kbe/deployments/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/deployments/</guid>
      <description>A deployment is a supervisor for pods, giving you fine-grained control over how and when a new pod version is rolled out as well as rolled back to a previous state.
Let&amp;rsquo;s create a deployment called sise-deploy that supervises two replicas of a pod as well as a replica set:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/deployments/d09.yaml You can have a look at the deployment, as well as the the replica set and the pods the deployment looks after like so:</description>
    </item>
    
    <item>
      <title>Environment Variables</title>
      <link>https://tonejito.github.io/kbe/envs/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/envs/</guid>
      <description>You can set environment variables for containers running in a pod and in addition, Kubernetes exposes certain runtime infos via environment variables automatically.
Let&amp;rsquo;s launch a pod that we pass an environment variable SIMPLE_SERVICE_VERSION with the value 1.0:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/envs/pod.yaml Now, let&amp;rsquo;s verify from within the cluster if the application running in the pod has picked up the environment variable SIMPLE_SERVICE_VERSION:
kubectl exec envs -t -- curl -s 127.</description>
    </item>
    
    <item>
      <title>Health Checks</title>
      <link>https://tonejito.github.io/kbe/healthz/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/healthz/</guid>
      <description>In order to verify if a container in a pod is healthy and ready to serve traffic, Kubernetes provides for a range of health checking mechanisms. Health checks, or probes as they are called in Kubernetes, are carried out by the kubelet to determine when to restart a container (for livenessProbe) and used by services and deployments to determine if a pod should receive traffic (for readinessProbe).
We will focus on HTTP health checks in the following.</description>
    </item>
    
    <item>
      <title>Labels</title>
      <link>https://tonejito.github.io/kbe/labels/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/labels/</guid>
      <description>Labels are the mechanism you use to organize Kubernetes objects. A label is a key-value pair with certain restrictions concerning length and allowed values but without any pre-defined meaning. So you&amp;rsquo;re free to choose labels as you see fit, for example, to express environments such as &amp;lsquo;this pod is running in production&amp;rsquo; or ownership, like &amp;lsquo;department X owns that pod&amp;rsquo;.
Let&amp;rsquo;s create a pod that initially has one label (env=development):</description>
    </item>
    
    <item>
      <title>Persistent Volumes</title>
      <link>https://tonejito.github.io/kbe/pv/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/pv/</guid>
      <description>A persistent volume (PV) is a cluster-wide resource that you can use to store data in a way that it persists beyond the lifetime of a pod. The PV is not backed by locally-attached storage on a worker node but by networked storage system such as EBS or NFS or a distributed filesystem like Ceph.
If you are using OpenShift Playground like us there already exist a few persistent volumes on your cluster.</description>
    </item>
    
    <item>
      <title>Replication Controllers</title>
      <link>https://tonejito.github.io/kbe/rcs/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/rcs/</guid>
      <description>A replication controller (RC) is a supervisor for long-running pods. An RC will launch a specified number of pods called replicas and makes sure that they keep running, for example when a node fails or something inside of a pod, that is, in one of its containers goes wrong.
Let&amp;rsquo;s create an RC that supervises a single replica of a pod:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/rcs/rc.yaml You can see the RC and the pod it looks after like so:</description>
    </item>
    
    <item>
      <title>Service Discovery</title>
      <link>https://tonejito.github.io/kbe/sd/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/sd/</guid>
      <description>Service discovery is the process of figuring out how to connect to a service. While there is a service discovery option based on environment variables available, the DNS-based service discovery is preferable. Note that Kube DNS is a cluster add-on, which means that it may need to installed, configured, or enabled in order to function correctly.
Let&amp;rsquo;s create a service named thesvc and an RC supervising some pods along with it:</description>
    </item>
    
    <item>
      <title>Services</title>
      <link>https://tonejito.github.io/kbe/services/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/services/</guid>
      <description>A service is an abstraction for pods, providing a stable, so called virtual IP (VIP) address. While pods may come and go and with it their IP addresses, a service allows clients to reliably connect to the containers running in the pod using the VIP. The virtual in VIP means it is not an actual IP address connected to a network interface, but its purpose is purely to forward traffic to one or more pods.</description>
    </item>
    
    <item>
      <title>Init Containers</title>
      <link>https://tonejito.github.io/kbe/ic/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/ic/</guid>
      <description>It&amp;rsquo;s sometimes necessary to prepare a container running in a pod. For example, you might want to wait for a service being available, want to configure things at runtime, or init some data in a database. In all of these cases, init containers are useful. Note that Kubernetes will execute all init containers (and they must all exit successfully) before the main container(s) are executed.
So let&amp;rsquo;s create an deployment consisting of an init container that writes a message into a file at /ic/this and the main (long-running) container reading out this file, then:</description>
    </item>
    
    <item>
      <title>Port Forward</title>
      <link>https://tonejito.github.io/kbe/pf/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/pf/</guid>
      <description>In the context of developing apps on Kubernetes it is often useful to quickly access a service from your local environment without exposing it using, for example, a load balancer or an ingress resource. In this case you can use port forwarding.
Let&amp;rsquo;s create an app consisting of a deployment and a service called simpleservice, serving on port 80:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/pf/app.yaml Let&amp;rsquo;s say we want to access the simpleservice service from the local environment, say, your laptop, on port 8080.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/metallb/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/metallb/install/</guid>
      <description>Guided Exercise: Installing MetalLB on a minikube cluster In this exercise, you will deploy the MetalLB add-on on a minikube cluster.
 Outcomes
 You should be able to:
   Create a minikube instance.
  Get the DHCP network parameters of the minikube VM driver.
  Enable and configure the MetalLB minikube add-on.
  Create an example deployment and LoadBalancer service.
  Access the service with the external IP address provided by MetalLB.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/metallb/metallb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/metallb/metallb/</guid>
      <description>MetalLB MetalLB is a load balancer suitable for local environments, it is included as an add-on in minikube.
   https://metallb.universe.tf/
         Home
 Next
      </description>
    </item>
    
  </channel>
</rss>
