<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes By Example</title>
    <link>https://tonejito.github.io/kbe/</link>
    <description>Recent content on Kubernetes By Example</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 10 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://tonejito.github.io/kbe/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DIY</title>
      <link>https://tonejito.github.io/kbe/diy/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/diy/</guid>
      <description>If you want to try out the examples here yourself, here are a couple of options:
OpenShift Playground You can use the OpenShift Playground to get access to a cluster for 60 minutes at a time. This option doesn&amp;rsquo;t require you to install anything. This is the option we used for most of the examples on the site.
OpenShift Playground
Click the red START SCENARIO button, and then you will have access to an OpenShift cluster via a web-based terminal window with kubectl available.</description>
    </item>
    
    <item>
      <title>Namespaces</title>
      <link>https://tonejito.github.io/kbe/ns/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/ns/</guid>
      <description>Namespaces provide a scope for Kubernetes resources, carving up your cluster in smaller units. You can think of it as a workspace you&amp;rsquo;re sharing with other users. Many resources such as pods and services are namespaced, while some, for example, nodes are not namespaced (but cluster-wide). As a developer you&amp;rsquo;d usually use an assigned namespace, however admins may wish to manage them, for example to set up access control or resource quotas.</description>
    </item>
    
    <item>
      <title>Nodes</title>
      <link>https://tonejito.github.io/kbe/nodes/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/nodes/</guid>
      <description>In Kubernetes, nodes are the (virtual) machines where your workloads in shape of pods run. As a developer you typically don&amp;rsquo;t deal with nodes directly, however as an admin you might want to familiarize yourself with node operations.
To list available nodes in your cluster (note that the output will depend on the environment you&amp;rsquo;re using. This example is using the OpenShift Playground):
kubectl get nodes  NAME STATUS ROLES AGE VERSION crc-rk2fc-master-0 Ready master,worker 102d v1.</description>
    </item>
    
    <item>
      <title>StatefulSet</title>
      <link>https://tonejito.github.io/kbe/statefulset/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/statefulset/</guid>
      <description>If you have a stateless app you want to use a deployment. However, for a stateful app you might want to use a StatefulSet. Unlike a deployment, the StatefulSet provides certain guarantees about the identity of the pods it is managing (that is, predictable names) and about the startup order. Two more things that are different compared to a deployment: for network communication you need to create a headless services and for persistency the StatefulSet manages a persistent volume per pod.</description>
    </item>
    
    <item>
      <title>Jobs</title>
      <link>https://tonejito.github.io/kbe/jobs/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/jobs/</guid>
      <description>A job in Kubernetes is a supervisor for pods carrying out batch processes, that is, a process that runs for a certain time to completion, for example a calculation or a backup operation.
Let&amp;rsquo;s create a job called countdown that supervises a pod counting from 9 down to 1:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/jobs/job.yaml  You can see the job and the pod it looks after like so:
kubectl get jobs  NAME DESIRED SUCCESSFUL AGE countdown 1 1 5s  kubectl get pods  NAME READY STATUS RESTARTS AGE countdown-qkjx8 0/1 Completed 0 2m17s  To learn more about the status of the job, do:</description>
    </item>
    
    <item>
      <title>Volumes</title>
      <link>https://tonejito.github.io/kbe/volumes/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/volumes/</guid>
      <description>A Kubernetes volume is essentially a directory accessible to all containers running in a pod. In contrast to the container-local filesystem, the data in volumes is preserved across container restarts. The medium backing a volume and its contents are determined by the volume type:
 node-local types such as emptyDir or hostPath file-sharing types such as nfs cloud provider-specific types like awsElasticBlockStore, azureDisk, or gcePersistentDisk distributed file system types, for example glusterfs or cephfs special-purpose types like secret, gitRepo  A special type of volume is PersistentVolume, which we will cover elsewhere.</description>
    </item>
    
    <item>
      <title>API Server access</title>
      <link>https://tonejito.github.io/kbe/api/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/api/</guid>
      <description>Sometimes it&amp;rsquo;s useful or necessary to directly access the Kubernetes API server, for exploratory or testing purposes.
In order to do this, one option is to proxy the API to your local environment, using:
kubectl proxy --port=8080  Starting to serve on 127.0.0.1:8080  Now you can query the API (in a separate terminal session) like so:
curl http://localhost:8080/api/v1  { &amp;quot;kind&amp;quot;: &amp;quot;APIResourceList&amp;quot;, &amp;quot;groupVersion&amp;quot;: &amp;quot;v1&amp;quot;, &amp;quot;resources&amp;quot;: [ { ... { &amp;quot;name&amp;quot;: &amp;quot;services/status&amp;quot;, &amp;quot;singularName&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;namespaced&amp;quot;: true, &amp;quot;kind&amp;quot;: &amp;quot;Service&amp;quot;, &amp;quot;verbs&amp;quot;: [ &amp;quot;get&amp;quot;, &amp;quot;patch&amp;quot;, &amp;quot;update&amp;quot; ] } ] }  Alternatively, without proxying, you can use kubectl directly as follows to achieve the same:</description>
    </item>
    
    <item>
      <title>Pods</title>
      <link>https://tonejito.github.io/kbe/pods/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/pods/</guid>
      <description>A pod is a collection of containers sharing a network and mount namespace and is the basic unit of deployment in Kubernetes. All containers in a pod are scheduled on the same node.
To launch a pod using the container image quay.io/openshiftlabs/simpleservice:0.5.0 and exposing a HTTP API on port 9876, execute:
kubectl run sise --image=quay.io/openshiftlabs/simpleservice:0.5.0 --port=9876  pod/sise created  Note: Deprecation Warning! Older releases of kubectl will produce a deployment resource as the result of the provided kubectl run example, while newer releases produce a single pod resource.</description>
    </item>
    
    <item>
      <title>Logging</title>
      <link>https://tonejito.github.io/kbe/logging/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/logging/</guid>
      <description>Logging is one option to understand what is going on inside your applications and the cluster at large. Basic logging in Kubernetes makes the output a container produces available, which is a good use case for debugging. More advanced setups consider logs across nodes and store them in a central place, either within the cluster or via a dedicated (cloud-based) service.
Let&amp;rsquo;s create a pod called logme that runs a container writing to stdout and stderr:</description>
    </item>
    
    <item>
      <title>Secrets</title>
      <link>https://tonejito.github.io/kbe/secrets/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/secrets/</guid>
      <description>You don&amp;rsquo;t want sensitive information such as a database password or an API key kept around in clear text. Secrets provide you with a mechanism to use such information in a safe and reliable way with the following properties:
 Secrets are namespaced objects, that is, exist in the context of a namespace You can access them via a volume or an environment variable from a container running in a pod The secret data on nodes is stored in tmpfs volumes A per-secret size limit of 1MB exists The API server stores secrets as plaintext in etcd  Let&amp;rsquo;s create a secret apikey that holds a (made-up) API key:</description>
    </item>
    
    <item>
      <title>Deployments</title>
      <link>https://tonejito.github.io/kbe/deployments/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/deployments/</guid>
      <description>A deployment is a supervisor for pods, giving you fine-grained control over how and when a new pod version is rolled out as well as rolled back to a previous state.
Let&amp;rsquo;s create a deployment called sise-deploy that supervises two replicas of a pod as well as a replica set:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/deployments/d09.yaml  You can have a look at the deployment, as well as the the replica set and the pods the deployment looks after like so:</description>
    </item>
    
    <item>
      <title>Environment Variables</title>
      <link>https://tonejito.github.io/kbe/envs/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/envs/</guid>
      <description>You can set environment variables for containers running in a pod and in addition, Kubernetes exposes certain runtime infos via environment variables automatically.
Let&amp;rsquo;s launch a pod that we pass an environment variable SIMPLE_SERVICE_VERSION with the value 1.0:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/envs/pod.yaml  Now, let&amp;rsquo;s verify from within the cluster if the application running in the pod has picked up the environment variable SIMPLE_SERVICE_VERSION:
kubectl exec envs -t -- curl -s 127.</description>
    </item>
    
    <item>
      <title>Health Checks</title>
      <link>https://tonejito.github.io/kbe/healthz/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/healthz/</guid>
      <description>In order to verify if a container in a pod is healthy and ready to serve traffic, Kubernetes provides for a range of health checking mechanisms. Health checks, or probes as they are called in Kubernetes, are carried out by the kubelet to determine when to restart a container (for livenessProbe) and used by services and deployments to determine if a pod should receive traffic (for readinessProbe).
We will focus on HTTP health checks in the following.</description>
    </item>
    
    <item>
      <title>Labels</title>
      <link>https://tonejito.github.io/kbe/labels/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/labels/</guid>
      <description>Labels are the mechanism you use to organize Kubernetes objects. A label is a key-value pair with certain restrictions concerning length and allowed values but without any pre-defined meaning. So you&amp;rsquo;re free to choose labels as you see fit, for example, to express environments such as &amp;lsquo;this pod is running in production&amp;rsquo; or ownership, like &amp;lsquo;department X owns that pod&amp;rsquo;.
Let&amp;rsquo;s create a pod that initially has one label (env=development):</description>
    </item>
    
    <item>
      <title>Persistent Volumes</title>
      <link>https://tonejito.github.io/kbe/pv/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/pv/</guid>
      <description>A persistent volume (PV) is a cluster-wide resource that you can use to store data in a way that it persists beyond the lifetime of a pod. The PV is not backed by locally-attached storage on a worker node but by networked storage system such as EBS or NFS or a distributed filesystem like Ceph.
If you are using OpenShift Playground like us there already exist a few persistent volumes on your cluster.</description>
    </item>
    
    <item>
      <title>Replication Controllers</title>
      <link>https://tonejito.github.io/kbe/rcs/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/rcs/</guid>
      <description>A replication controller (RC) is a supervisor for long-running pods. An RC will launch a specified number of pods called replicas and makes sure that they keep running, for example when a node fails or something inside of a pod, that is, in one of its containers goes wrong.
Let&amp;rsquo;s create an RC that supervises a single replica of a pod:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/rcs/rc.yaml  You can see the RC and the pod it looks after like so:</description>
    </item>
    
    <item>
      <title>Service Discovery</title>
      <link>https://tonejito.github.io/kbe/sd/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/sd/</guid>
      <description>Service discovery is the process of figuring out how to connect to a service. While there is a service discovery option based on environment variables available, the DNS-based service discovery is preferable. Note that Kube DNS is a cluster add-on, which means that it may need to installed, configured, or enabled in order to function correctly.
Let&amp;rsquo;s create a service named thesvc and an RC supervising some pods along with it:</description>
    </item>
    
    <item>
      <title>Services</title>
      <link>https://tonejito.github.io/kbe/services/</link>
      <pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/services/</guid>
      <description>A service is an abstraction for pods, providing a stable, so called virtual IP (VIP) address. While pods may come and go and with it their IP addresses, a service allows clients to reliably connect to the containers running in the pod using the VIP. The virtual in VIP means it is not an actual IP address connected to a network interface, but its purpose is purely to forward traffic to one or more pods.</description>
    </item>
    
    <item>
      <title>Init Containers</title>
      <link>https://tonejito.github.io/kbe/ic/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/ic/</guid>
      <description>It&amp;rsquo;s sometimes necessary to prepare a container running in a pod. For example, you might want to wait for a service being available, want to configure things at runtime, or init some data in a database. In all of these cases, init containers are useful. Note that Kubernetes will execute all init containers (and they must all exit successfully) before the main container(s) are executed.
So let&amp;rsquo;s create an deployment consisting of an init container that writes a message into a file at /ic/this and the main (long-running) container reading out this file, then:</description>
    </item>
    
    <item>
      <title>Port Forward</title>
      <link>https://tonejito.github.io/kbe/pf/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/pf/</guid>
      <description>In the context of developing apps on Kubernetes it is often useful to quickly access a service from your local environment without exposing it using, for example, a load balancer or an ingress resource. In this case you can use port forwarding.
Let&amp;rsquo;s create an app consisting of a deployment and a service called simpleservice, serving on port 80:
kubectl apply -f https://raw.githubusercontent.com/openshift-evangelists/kbe/main/specs/pf/app.yaml  Let&amp;rsquo;s say we want to access the simpleservice service from the local environment, say, your laptop, on port 8080.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/deployments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/deployments/</guid>
      <description>Deployments A deployment is a supervisor for pods, giving you fine-grained control over how and when a new pod version is rolled out as well as rolled back to a previous state.
Let&amp;rsquo;s create a deployment called sise-deploy that produces two replicas of a pod as well as a replica set:
$ kubectl apply -f https://github.com/openshift-evangelists/kbe/raw/main/specs/deployments/d09.yaml  You can have a look at the deployment, as well as the the replica set and the pods the deployment looks using the get subcommand (multiple resource types may be specified in a single call):</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/environment-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/environment-variables/</guid>
      <description>Environment Variables You can set environment variables for containers running in a pod. Additionally, Kubernetes automatically exposes certain runtime information via environment variables.
Let&amp;rsquo;s launch a pod that we pass an environment variable SIMPLE_SERVICE_VERSION with the value 1.0:
$ kubectl apply -f https://github.com/openshift-evangelists/kbe/raw/main/specs/envs/pod.yaml  Now, let&amp;rsquo;s verify from within the cluster if the application running in the pod has picked up the environment variable:
$ kubectl exec envs -t -- curl -s 127.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/environment-variables.old/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/environment-variables.old/</guid>
      <description>Environment Variables You can set environment variables for containers running in a pod. Additionally, Kubernetes automatically exposes certain runtime information via environment variables.
Create a pod of the simple service application using the container image on the quay.io registry.
$ kubectl run envs --image=quay.io/openshiftlabs/simpleservice:0.5.0 --port=9876 $ kubectl get pods NAME READY STATUS RESTARTS AGE envs 1/1 Running 0 20s  View the environment variables defined in the pod.
$ kubectl describe pod envs | grep &#39;Environment:&#39; Environment: &amp;lt;none&amp;gt;  Access the application and display the service version.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/health-checks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/health-checks/</guid>
      <description>Health Checks In order to verify if a container in a pod is healthy and ready to serve traffic, Kubernetes provides for a range of health checking mechanisms. Health checks, or probes as they are called in Kubernetes, are carried out by the kubelet to determine when to restart a container (liveness probes) and used by services and deployments to determine if a pod should receive traffic (readiness probes).
We will focus on HTTP health checks in the following.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/jobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/jobs/</guid>
      <description>Jobs A job in Kubernetes is a supervisor for pods that run for a certain time to completion, for example a calculation or a backup operation.
Let&amp;rsquo;s create a job named countdown that supervises a pod counting from 9 down to 1:
$ kubectl apply -f https://github.com/openshift-evangelists/kbe/raw/main/specs/jobs/job.yaml  The job definition is listed under the resource type job:
$ kubectl get jobs  A job is executed as a pod. Unlike most pods, however, the pod spawned by a job does not continue to run, but will instead reach a Completed state.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/jobs.old/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/jobs.old/</guid>
      <description>Jobs A job in Kubernetes is a supervisor for pods that run for a certain time to completion, for example a calculation or a backup operation.
Let&amp;rsquo;s create a job named countdown that supervises a pod counting from 9 down to 1.
$ $ kubectl apply -f https://github.com/openshift-evangelists/kbe/raw/main/specs/jobs/job.yaml job.batch/countdown created  The job definition is listed under the resource type job.
$ kubectl get jobs NAME COMPLETIONS DURATION AGE countdown 1/1 1s 10s  A job is executed as a pod.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/labels/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/labels/</guid>
      <description>Labels Labels are the mechanism used to organize Kubernetes objects. A label is a key-value pair with certain restrictions concerning length and allowed values but without any pre-defined meaning. You&amp;rsquo;re free to choose labels as you see fit, for example, to express environments such as &amp;ldquo;this pod is running in production&amp;rdquo; or ownership, like &amp;ldquo;department X owns that pod&amp;rdquo;.
aaa bbb ccc
Let&amp;rsquo;s create a pod that initially has one label (env=development):</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/logging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/logging/</guid>
      <description>Logging Logging is one option to understand what is going on inside your applications and the cluster at large. Basic logging in Kubernetes makes the output a container produces available through the kubectl tool. More advanced setups consider logs across nodes and store them in a central place, either within the cluster or via a dedicated (cloud-based) service.
Let&amp;rsquo;s create a pod called logme that runs a container writing to stdout and stderr:</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/namespaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/namespaces/</guid>
      <description>Namespaces Namespaces provide a scope for Kubernetes resources, carving up your cluster in smaller units.
You can think of it as a workspace you&amp;rsquo;re sharing with other users. Many resources such as pods and services are namespaced. Others, such as nodes, are not namespaced, but are instead treated as cluster-wide.
As a developer, you&amp;rsquo;ll usually use an assigned namespace, however admins may wish to manage them, for example to set up access control or resource quotas.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/nodes/</guid>
      <description>Nodes In Kubernetes, nodes are the (potentially virtual) machines where your workloads run. As a developer, you typically don&amp;rsquo;t deal with nodes directly, however as an admin you might want to familiarize yourself with node operations.
Node information is captured in a resource type named node:
$ kubectl get nodes  The output will vary depending on your cluster. The example below is taken from a minikube cluster:
NAME STATUS ROLES AGE VERSION minikube Ready control-plane,master 42m v1.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/persistent-volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/persistent-volumes/</guid>
      <description>Persistent Volumes A persistent volume (PV) is a cluster-wide resource that you can use to store data in a way that it persists beyond the lifetime of a pod. The PV is not backed by locally-attached storage on a worker node but by networked storage system such as EBS or NFS or a distributed filesystem like Ceph.
Depending on your cluster and storage type, the configuration of a PV will vary slightly.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/persistent-volumes.old/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/persistent-volumes.old/</guid>
      <description>Persistent Volume A persistent volume (PV) is a cluster-wide resource that you can use to store data in a way that it persists beyond the lifetime of a pod. The PV is not backed by locally-attached storage on a worker node but by networked storage system such as EBS or NFS or a distributed filesystem like Ceph.
Depending on your cluster and storage type, the configuration of a PV will vary slightly.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/pods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/pods/</guid>
      <description>Pods A pod is a collection of containers sharing a network, acting as the basic unit of deployment in Kubernetes. All containers in a pod are scheduled on the same node.
To launch a pod using the container image quay.io/openshiftlabs/simpleservice:0.5.0 and exposing a HTTP API on port 9876, execute:
$ kubectl run sise --image=quay.io/openshiftlabs/simpleservice:0.5.0 --port=9876   Warning: Older releases of kubectl will produce a deployment resource as the result of the provided kubectl run example, while newer releases produce a single pod resource.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/port-forwarding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/port-forwarding/</guid>
      <description>Port Forwarding In the context of developing applications on Kubernetes, it is often useful to quickly access a service from your local environment without exposing it using, for example, a load balancer or an ingress resource. In these situations, you can use port forwarding.
Let&amp;rsquo;s create an application consisting of a deployment and a service named simpleservice, serving on port 80:
$ kubectl apply -f https://github.com/openshift-evangelists/kbe/raw/main/specs/pf/app.yaml  Let&amp;rsquo;s say we want to access the simpleservice service from the local environment on port 8080.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/secrets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/secrets/</guid>
      <description>Secrets You don&amp;rsquo;t want sensitive information such as a database password or an API key stored in clear text. Secrets provide you with a mechanism to store such information in a safe and reliable way with the following properties:
 Secrets are namespaced objects, that is, exist in the context of a specific namespace You can access them via a volume or an environment variable from a container running in a pod The secret data on nodes is stored in tmpfs volumes A per-secret size limit of 1MB exists The API server stores secrets as plaintext in etcd  Let&amp;rsquo;s create a secret named apikey that holds an example API key.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/services/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/services/</guid>
      <description>Services A service is an abstraction for pods, providing a stable, so called virtual IP (VIP) address. While pods may come and go and with it their IP addresses, a service allows clients to reliably connect to the containers running in the pod using the VIP.
The virtual in VIP means it is not an actual IP address connected to a network interface, but its purpose is purely to forward traffic to one or more pods.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/concepts/volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/concepts/volumes/</guid>
      <description>Volumes A Kubernetes volume is essentially a directory accessible to all containers running in a pod. In contrast to the container-local filesystem, the data in volumes is preserved across container restarts. The medium backing a volume and its contents are determined by the volume type:
 node-local types such as emptyDir or hostPath file-sharing types such as nfs cloud provider-specific types like awsElasticBlockStore, azureDisk, or gcePersistentDisk distributed file system types, for example glusterfs or cephfs special-purpose types like secret, gitRepo  A special type of volume is PersistentVolume, which is covered in its own lesson.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubectl-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubectl-practice/</guid>
      <description>Guided Exercise: Connecting kubectl to Your Cluster In this exercise you will install the kubectl command-line tool on your computer, and connect to the Kubernetes cluster that you will be using throughout the course.
Outcomes You should be able to:
 Install kubectl Connect to minikube (in case you are using it) Connect to the OpenShift Developer Sandbox (in case you are using it)  Prerequisites Ensure you have either installed minikube or created an OpenShift Developer Sandbox account.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubectl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubectl/</guid>
      <description>Introducing kubectl Objectives After completing this section, you should be able to review the basic usage of the kubectl command and understand how to connect to your Kubernetes cluster by using the CLI.
Introducing kubectl The kubectl tool is a Kubernetes command-line tool that allows you to interact with your Kubernetes cluster. It provides an easy way to perform tasks such as creating resources or redirecting cluster traffic. The kubectl tool is available for the three main operating systems (Linux, Windows and macOS).</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubernetes-distributions-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubernetes-distributions-practice/</guid>
      <description>Guided Exercise: Contrasting Kubernetes Distributions In this exercise you will prepare your development environment to use a local or remote Kubernetes instance.
Outcomes You should be able to:
 Install a local Kubernetes instance by using minikube on Linux, macOS or Windows. Register for using a remote Kubernetes instance by using Developer Sandbox for Red Hat OpenShift.  Instructions  Note Installing a local Kubernetes cluster requires administrative privileges in your development workstation.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubernetes-distributions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/kubernetes-distributions/</guid>
      <description>Contrasting Kubernetes Distributions Objectives After completing this section, you should be able to see the differences between several Kubernetes implementations, and understand how to prepare different Kubernetes flavors for this course.
Kubernetes Distributions Kubernetes has historically been a general solution for container management and orchestration. With this versatility, Kubernetes can solve the same problems in different ways depending on needs and opinions. Because of this Kubernetes has evolved into different opinionated distributions based on:</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/running-applications-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/running-applications-practice/</guid>
      <description>Guided Exercise: Running and Interacting with Your First Application In this exercise, you will create a pod and connect to it. You will also create and manage a new namespace resource by using a resource definition file that you create.
Outcomes You should be able to:
 Connect a shell session to an existing pod. Create a resource definition file. Use a resource definition to create and update a namespace resource.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/running-applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-1/running-applications/</guid>
      <description>Running and Interacting with Your First Application Objectives After completing this section, you should be able to execute a pre-built application in your Kubernetes cluster and review the resources related to the process.
Running Pods From Container Images The simplest way to run a container in your Kubernetes cluster is with the kubectl run command. At a minimum, you must specify a name and container image. This container image must be accessible by the Kubernetes cluster.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-2/managed-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-2/managed-practice/</guid>
      <description>Guided Exercise: Deploying Managed Applications In this exercise you will deploy a managed containerized application in your Kubernetes cluster. You will observe how automatic deployment works and some of the High Availability features of Kubernetes.
Outcomes You should be able to:
 Deploy an application container with several replicas. Review the structure of the Deployment resource manifest. Update the application to a new version without losing availability.  Prerequisites You need a working Kubernetes cluster, and your kubectl command must be configured to communicate with the cluster.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-2/managed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-2/managed/</guid>
      <description>Deploying Managed Applications Objectives After completing this section, you should be able to use Kubernetes container management capabilities to deploy containerized applications in a declarative way.
Managing Containers One of the most significant features of Kubernetes is that it enables developers to use a declarative approach for automatic container life cycle management. Declarative approach means developers declare what should be the status of the application, and Kubernetes will update the containers to reach that state.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-external-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-external-practice/</guid>
      <description>Guided Exercise: Exposing Applications for External Access In this exercise you will provide external access to a service running inside your Kubernetes cluster.
Outcomes You should be able to:
  Verify that the service IP address and the associated pod IP addresses for an application are not accessible outside of the cluster.
  Create an ingress resource to provide external access to an application service.
  Confirm that the ingress redirects traffic to the service.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-external/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-external/</guid>
      <description>Exposing Applications for External Access Objectives After completing this section, you should be able to expose service-backed applications to clients outside the Kubernetes cluster.
Kubernetes Ingress Kubernetes assigns IP addresses to pods and services. Pod and service IP addresses are not usually accessible outside of the cluster. Unless prevented by network policies, the Kubernetes cluster typically allows internal communication between pods and services. This internal communication allows application pods to interact with services that are not externally accessible, such as database services.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-internal-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-internal-practice/</guid>
      <description>Guided Exercise: Exposing Applications for Internal Access In this exercise you will deploy two apps in different namespaces. They communicate by using the built-in Kubernetes DNS resolution system.
Outcomes You should be able to:
 Create a service using kubectl expose Create a service using a manifest Use DNS resolution for service communication  Prerequisites Ensure that:
 Minikube and kubectl are running on your machine You have cloned the DO100-apps repository You have executed the setup script  Instructions To illustrate how communication is handled in Kubernetes, you use two applications.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-internal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-3/expose-internal/</guid>
      <description>Exposing Applications for Internal Access Objectives After completing this section, you should be able to enable intra-pod network communications for applications deployed in Kubernetes, and learn how to keep communication up even with automatic deployments.
Kubernetes Networking When pods are created, they are assigned an IP address. You use this IP to access the pod from anywhere within the Kubernetes cluster. Containers inside a pod share the same network space, which means that, within the pod, containers can communicate with each other by using the localhost address.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/cloud-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/cloud-practice/</guid>
      <description>Guided Exercise: Configuring Cloud Applications Injecting Configuration Data into an Application In this exercise, you will use configuration maps and secrets to externalize the configuration for a containerized application.
Outcomes You should be able to:
  Deploy a simple Node.js-based application that prints configuration details from environment variables and files.
  Inject configuration data into the container using configuration maps and secrets.
  Change the data in the configuration map and verify that the application picks up the changed values.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/cloud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/cloud/</guid>
      <description>Configuring Cloud Applications Objectives After completing this section, you should be able to create Kubernetes resources holding application configuration and secrets, and how to make that configuration available to running applications.
Externalizing Application Configuration in Kubernetes Developers configure their applications through a combination of environment variables, command-line arguments, and configuration files. When deploying applications to Kubernetes, configuration management presents a challenge due to the immutable nature of containers. When running containerized applications, decoupling application and configuration code is of a higher priority than in traditional deployments.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/limit-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/limit-practice/</guid>
      <description>Guided Exercise: Limiting Resource Usage Outcomes You should be able to use the Kubernetes command-line interface to:
  Configure an application to specify resource requests for CPU and memory usage.
  Modify an application to work within existing cluster restrictions.
  Prerequisites You need a working Kubernetes cluster, and your kubectl command must be configured to communicate with the cluster.
Make sure your kubectl context refers to a namespace where you have enough permissions, usually username-dev or username-stage.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/limit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/limit/</guid>
      <description>Limiting Resource Usage Objectives After completing this section, you should be able to leverage how to avoid applications overusing system resources.
Defining Resource Requests and Limits for Pods A pod definition can include both resource requests and resource limits:
 Resource requests Used for scheduling and indicating that a pod cannot run with less than the specified amount of compute resources. The scheduler tries to find a node with sufficient compute resources to satisfy the requests.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/probes-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/probes-practice/</guid>
      <description>Guided Exercise: Liveness, Readiness, and Startup Probes Activating Probes In this exercise, you will configure liveness and readiness probes to monitor the health of an application deployed to your Kubernetes cluster.
The application you deploy in this exercise exposes two HTTP GET endpoints:
  The /healthz endpoint responds with a 200 HTTP status code when the application pod can receive requests.
The endpoint indicates that the application pod is healthy and reachable.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/probes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-4/probes/</guid>
      <description>Liveness, Readiness, and Startup Probes Objectives After completing this section, you should be able to review how Kubernetes evaluates application health status via probes and automatic application restart.
Kubernetes Readiness and Liveness Probes Applications can become unreliable for a variety of reasons, for example:
 Temporary connection loss Configuration errors Application errors  Developers can use probes to monitor their applications. Probes make developers aware of events such as application status, resource usage, and errors.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-5/strategies-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-5/strategies-practice/</guid>
      <description>Guided Exercise: Implementing Cloud Deployment Strategies Outcomes You should be able to:
  Deploy an application container with several replicas.
  Review the structure of the Deployment resource manifest.
  Update the application to a new version without losing availability.
  Prerequisites You need a working Kubernetes cluster, and your kubectl command must be configured to communicate with the cluster.
Make sure your kubectl context refers to a namespace where you have enough permissions, usually username-dev or username-stage.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-5/strategies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/learning-paths/application-development/lesson-5/strategies/</guid>
      <description>Implementing Cloud Deployment Strategies Deployment Strategies in Kubernetes A deployment strategy is a method of changing or upgrading an application. The objective is to make changes or upgrades with minimal downtime and with reduced impact on end users.
Kubernetes provides several deployment strategies. These strategies are organized into two primary categories:
  By using the deployment strategy defined in the application deployment.
  By using the Kubernetes router to route traffic to specific application pods.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/istio/gateway-virtualservice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/istio/gateway-virtualservice/</guid>
      <description>‚è™
 üè†
 ¬†     Guided Exercise: Configuring Istio Traffic Management In this exercise, you will configure the amount of traffic that is routed to the back-end services by using virtual services and destination rules.
 Outcomes
 You should be able to:
   Deploy the book info application in the Kubernetes cluster.
  Configure the gateway, virtual services, and destination rules to manage ingress traffic.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/istio/ingress-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/istio/ingress-control/</guid>
      <description>‚è™
 üè†
 ‚è©
     Istio Ingress Control Istio implements the Kubernetes ingress resource to expose a service and make it accessible from outside the cluster.
   Note  The general recommendation is to use Istio gateway, and virtual service resources to allow a more complete control over the traffic. That content is covered in the traffic management section.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/istio/ingress/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/istio/ingress/</guid>
      <description>‚è™
 üè†
 ‚è©
     Guided Exercise: Configuring Istio Ingress Control In this exercise, you will configure the ingress resource to access the Kubernetes dashboard.
 Outcomes
 You should be able to:
   Deploy the Kubernetes dashboard add-on in the minikube cluster.
  Configure the ingress resource to access the application from outside the cluster.
   To perform this exercise, ensure that you have:</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/istio/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/istio/install/</guid>
      <description>‚è™
 üè†
 ‚è©
     Guided Exercise: Installing Istio on a Minikube Cluster In this exercise, you will install Istio on a minikube cluster.
 Outcomes
 You should be able to:
   Install Istio on the minikube cluster.
  Get the Istio ingress service endpoint.
  Deploy the Istio add-ons.
  Create an example application to test the Istio installation.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/istio/istio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/istio/istio/</guid>
      <description>üè†
 ‚è©
     Istio Istio is an ingress controller and a service mesh implementation for Kubernetes. It abstracts the traffic management logic from the application by using a sidecar container that manages all the incoming and outgoing network traffic for a pod.
 Before Istio, applications managed all the advanced network operations, retry logic and resiliency, which added complexity to the main logic.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/istio/traffic-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/istio/traffic-management/</guid>
      <description>‚è™
 üè†
 ‚è©
     Istio Traffic Management Istio implements support for the standard Kubernetes ingress resource, but the functionality is limited. The full traffic management features of Istio can be configured with the following CRDs.
  Gateway
  Virtual service
  Destination rule
   Gateway The gateway resource specifies what happens when the traffic is entering or leaving the cluster.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/metallb/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/metallb/install/</guid>
      <description>‚è™
 üè†
 ¬†     Guided Exercise: Installing Metallb on a Minikube Cluster In this exercise, you will deploy the MetalLB add-on on a minikube cluster.
 Outcomes
 You should be able to:
   Create a minikube instance.
  Get the DHCP network parameters of the minikube VM driver.
  Enable and configure the MetalLB minikube add-on.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tonejito.github.io/kbe/topics/metallb/metallb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tonejito.github.io/kbe/topics/metallb/metallb/</guid>
      <description>üè†
 ‚è©
     MetalLB The Kubernetes clusters deployed in cloud environments use the functionality from the provider to dynamically provision managed load balancers for the services of type LoadBalancer. MetalLB implements the load balancer functionality for local or bare metal Kubernetes clusters that are not deployed in cloud environments.
 Kubernetes Service Types Kubernetes has three types of services:</description>
    </item>
    
  </channel>
</rss>
